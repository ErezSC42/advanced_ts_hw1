{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro"
    ]
   },
   "source": [
    "# Grading process\n",
    "\n",
    "\n",
    "The submission notebook will be autovalidated with `papermill`. The exact command is the following:\n",
    "\n",
    "```bash\n",
    "papermill <notebook-name>.ipynb <notebook-name>-run.ipynb .ipynb -p TEST True\n",
    "```\n",
    "\n",
    "Papermill will inject new cell after each cell tagged as `parameters` (see `View > Cell toolbar > Tags`). Notebook will be executed from top to bottom in a linear order. `solutions.py` contains correct implementations used to validate your solutions.\n",
    "\n",
    "Please, **fill `STUDENT` variable with the name of submitting student**, so that we can collect the results automatically. Please, **do not change `TEST` variable** and `validation` cells. If you need to inject your own code for testing, wrap it into\n",
    "\n",
    "```python\n",
    "if not TEST:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Different problems give different number of points. All problems in the basic section give 1 point, while all problems in intermediate section give 2 points.\n",
    "\n",
    "Each problem contains specific validation details. You need to fill each cell tagged `solution` with your code. Note, that solution function must self-contained, i.e. it must not use any state from the notebook itself.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "All problems in the assignment use [electricity load dataset](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014). Some functions/methods accept data itself, and in that case it's a Pandas dataframe as obtained by\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"LD2011_2014.txt\",\n",
    "                 parse_dates=[0],\n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "In contrast, whenever a function/method accepts a filename, it's the filename of **unzipped** data file (i.e. `LD2011_2014.txt`). When testing, do not rely on any specific location of the dataset, as validation environment will most certainly different from your local one. Hence, calls like\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"<your-local-directory>/LD2011_2014.txt\")\n",
    "```\n",
    "\n",
    "will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.111972Z",
     "start_time": "2019-10-30T22:26:04.107385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.372936Z",
     "start_time": "2019-10-30T22:26:04.364608Z"
    }
   },
   "outputs": [],
   "source": [
    "STUDENT = \"Erez Shwarts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ASSIGNMENT = 1\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:38.188583Z",
     "start_time": "2019-10-30T22:39:38.182534Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    import solutions\n",
    "    total_grade = 0\n",
    "    MAX_POINTS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 1. Resample the dataset (1 point)\n",
    "\n",
    "Resample the dataset to 1-hour resolution. Use `mean` as an aggregation function. Your function must output a dataframe, with the same structure as the original one (i.e. not indexed by datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"LD2011_2014.txt\",\n",
    "                 parse_dates=[0],\n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.100307Z",
     "start_time": "2019-10-30T22:26:07.092132Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def el_resample(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.set_index(\"timestamp\", inplace=True)\n",
    "    return df_copy.resample(\"H\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.334174Z",
     "start_time": "2019-10-30T22:26:07.322103Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 1\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, el_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 2. Consumption peaks (1 point)\n",
    "\n",
    "For each household, calculate, which month in 2014 had the highest consumption. Your function must output series, indexed by household ID (e.g., `MT_XXX`), and containing month as an integer (`1-12`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.274476Z",
     "start_time": "2019-10-30T22:26:08.268426Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def cons_peak(df):\n",
    "    CHOSEN_YEAR = 2014\n",
    "    copy_df = df.copy()\n",
    "    copy_df = copy_df[copy_df[\"timestamp\"].dt.year == CHOSEN_YEAR]\n",
    "    copy_df[\"month\"] = copy_df[\"timestamp\"].dt.month\n",
    "    return copy_df.groupby(\"month\").agg(\"sum\").idxmax(axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.554208Z",
     "start_time": "2019-10-30T22:26:08.542546Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 2\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, cons_peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 3. Find minimum (2 points)\n",
    "\n",
    "Consider the following scalar function:\n",
    "\n",
    "$$\n",
    "f(x) = ax^2 + bx + c\n",
    "$$\n",
    "\n",
    "Given $a,b,c$, find $x$, which minimizes $f(x)$, and minimum value of $f(x)$. Note this:\n",
    "\n",
    "- $a,b,c$ are fixed, and generated in such a way, that minimum always exists ($f(x)$ is convex),\n",
    "- $x$ is a scalar value, i.e. 0-dimensional tensor.\n",
    "\n",
    "For reference, see `generate_coef` function, which is used to generate coefficients. Note, that since optimization process is not completely deterministic, the output is considered correct, if it falls within `1e-3` of actual values.\n",
    "\n",
    "This problem must be solved as an optimization one using gradient descent.\n",
    "\n",
    "For that, use only PyTorch functionality, `SciPy` (or alike) optimization routines are not allowed, neither is direct calculation using coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coeffs():\n",
    "    a = torch.rand(size=()) * 10\n",
    "    b = -10 + torch.rand(size=()) * 10\n",
    "    c = -10 + torch.rand(size=()) * 10\n",
    "    print(a, b, c)\n",
    "    return a, b, c\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return x.pow(2) * a + x * b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3511) tensor(-8.1222) tensor(-4.9966)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a,b,c = generate_coeffs()\n",
    "\n",
    "x = torch.tensor(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.730308532714844 tensor(28.6560)\n",
      "-5.2329254150390625 tensor(-7.7437)\n",
      "-7.420960903167725 tensor(2.0926)\n",
      "-7.580739974975586 tensor(-0.5655)\n",
      "-7.5924072265625 tensor(0.1528)\n",
      "-7.593259811401367 tensor(-0.0413)\n",
      "-7.593321800231934 tensor(0.0112)\n",
      "-7.593326568603516 tensor(-0.0030)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-52dec7b9f869>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_iter = torch.tensor(10 * torch.rand(size=()), requires_grad=True)\n",
      "<ipython-input-5-52dec7b9f869>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_iter = torch.tensor(x_iter - MEU * grad, requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-7.593326568603516, tensor(0.6395, requires_grad=True))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_min(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.950073Z",
     "start_time": "2019-10-30T22:26:08.944541Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def find_min(a, b, c):\n",
    "    \n",
    "    EPS = 1e-2\n",
    "    MEU = 0.1\n",
    "\n",
    "    # using convex optimization methods\n",
    "    # return x_min, val_min\n",
    "    \n",
    "    # making sure x_iter is leaf so autograd will function correctly\n",
    "    x_iter = torch.tensor(10 * torch.rand(size=()), requires_grad=True) \n",
    "    grad = torch.tensor(1.)\n",
    "    \n",
    "    while torch.norm(grad) > EPS:\n",
    "        target_tensor = func(x_iter, a, b, c)\n",
    "        target_tensor.backward()\n",
    "        grad = x_iter.grad\n",
    "        print(target_tensor.item(), grad)\n",
    "        x_iter = torch.tensor(x_iter - MEU * grad, requires_grad=True)\n",
    "         \n",
    "    return target_tensor.item(), x_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.170219Z",
     "start_time": "2019-10-30T22:26:09.158251Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 3\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, find_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 4. PyTorch `Dataset` (3 points)\n",
    "\n",
    "Implement a `torch.utils.data.Dataset` sub-class for the electricity consumption data. Individual training instances must be week-long univarite series of hourly consumption (input, 168 values), followed by 24-hours long series of hourly consumption (output, 24 values) for a single household. Such a class can be used when training a consumption forecast model, which uses 7 days of historical consumption to forecast next 24 hours of consumption.\n",
    "\n",
    "`__getitem__(self, idx)` must return a tuple of 1D tensors, `in_data` and `out_data`. `in_data` contains 168 hours of consumption (hourly), starting from some `start_ts`, while `out_data` must contain 24 hourly consumption values starting from `start_ts + 168 hours` for some household. `start_ts` should be sampled randomly.\n",
    "\n",
    "Also, you need to implement a `get_mapping(self, idx)` method, which allows to calculate `(household, starting time) -> idx` correspondence.\n",
    "\n",
    "This class will be validated as the following:\n",
    "\n",
    "- dataset object is created with some random `samples`: `dataset = ElDataset(df, samples)` ,\n",
    "- validator fetches random `idx` (between `0` and `len(dataset)`) from the dataset:\n",
    "```python\n",
    "household, start_ts = dataset.get_mapping(idx)\n",
    "hist_data, future_data = dataset[idx]\n",
    "```\n",
    "- then, `hist_data` and `future_data` are compared with the data, obtained directly from `df` using `household, start_ts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iter_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-c2fee8a1b07e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0mcur_y_sample\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhousehold_series\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mts_index\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mX_SEQUENCE_LEN\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mts_index\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mPRED_OFFSET\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0mlist_item\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mhousehold\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimestamps_series\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mts_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_x_sample\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_y_sample\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m         \u001B[0miter_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist_item\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'iter_list' is not defined"
     ]
    }
   ],
   "source": [
    "temp_df = el_resample(df)\n",
    "temp_df.reset_index(inplace=True)\n",
    "\n",
    "SAMPLES = 100\n",
    "X_SEQUENCE_LEN = 168\n",
    "Y_SEQUENCE_LEN = 24\n",
    "PRED_OFFSET = X_SEQUENCE_LEN + Y_SEQUENCE_LEN\n",
    "NUM_HOUSEHOLDS = len(temp_df.columns.tolist()[1:]) \n",
    "DATA_LEN = len(temp_df)\n",
    "\n",
    "timestamps_series = temp_df.iloc[:,0]\n",
    "chosen_indexes = np.random.choice(DATA_LEN - (X_SEQUENCE_LEN + Y_SEQUENCE_LEN), (NUM_HOUSEHOLDS, SAMPLES))\n",
    "\n",
    "households = temp_df.columns.tolist()[1:]\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for household_index,household in enumerate(households):\n",
    "    household_series = temp_df[household]\n",
    "    for ts_index in chosen_indexes[household_index,:]:\n",
    "        cur_x_sample = torch.tensor(household_series[ts_index:ts_index+X_SEQUENCE_LEN].values)\n",
    "        cur_y_sample = torch.tensor(household_series[ts_index+X_SEQUENCE_LEN: ts_index + PRED_OFFSET].values)\n",
    "        list_item = (household, timestamps_series[ts_index], cur_x_sample, cur_y_sample)\n",
    "        iter_list.append(list_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.531869Z",
     "start_time": "2019-10-30T22:26:09.523705Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "class ElDataset(Dataset):\n",
    "    \"\"\"Electricity dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, samples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: original electricity data (see HW intro for details).\n",
    "            samples (int): number of sample to take per household.\n",
    "        \"\"\"\n",
    "        X_SEQUENCE_LEN = 168\n",
    "        Y_SEQUENCE_LEN = 24\n",
    "        PRED_OFFSET = X_SEQUENCE_LEN + Y_SEQUENCE_LEN\n",
    "        \n",
    "        self.raw_data = df.reset_index()\n",
    "        \n",
    "        NUM_HOUSEHOLDS = len(self.raw_data.columns.tolist()[1:]) \n",
    "        DATA_LEN = len(self.raw_data)\n",
    "        \n",
    "        self.samples = samples\n",
    "        self.data_list = []\n",
    "        \n",
    "        timestamps_series = self.raw_data.iloc[:,0]\n",
    "        chosen_indexes = np.random.choice(DATA_LEN - (X_SEQUENCE_LEN + Y_SEQUENCE_LEN), (NUM_HOUSEHOLDS, samples))\n",
    "\n",
    "        households = self.raw_data.columns.tolist()[1:]\n",
    "\n",
    "        for household_index,household in enumerate(households):\n",
    "            household_series = self.raw_data[household]\n",
    "            for ts_index in chosen_indexes[household_index,:]:\n",
    "                cur_x_sample = torch.tensor(household_series[ts_index:ts_index+X_SEQUENCE_LEN].values)\n",
    "                cur_y_sample = torch.tensor(household_series[ts_index+X_SEQUENCE_LEN: ts_index + PRED_OFFSET].values)\n",
    "                list_item = (household, timestamps_series[ts_index], cur_x_sample, cur_y_sample)\n",
    "                self.data_list.append(list_item)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples * (self.raw_data.shape[1] - 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # return hist_data, future_data\n",
    "        data_entry = self.data_list[idx]\n",
    "        return data_entry[2], data_entry[3]\n",
    "\n",
    "    def get_mapping(self, idx):\n",
    "        # your code goes here\n",
    "        data_entry = self.data_list[idx]\n",
    "        return data_entry[0], data_entry[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-c42fc24cf924>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraw_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "ds.raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "MT_001\n",
      "MT_002\n",
      "MT_003\n",
      "MT_004\n",
      "MT_005\n",
      "MT_006\n",
      "MT_007\n",
      "MT_008\n",
      "MT_009\n",
      "MT_010\n",
      "MT_011\n",
      "MT_012\n",
      "MT_013\n",
      "MT_014\n",
      "MT_015\n",
      "MT_016\n",
      "MT_017\n",
      "MT_018\n",
      "MT_019\n",
      "MT_020\n",
      "MT_021\n",
      "MT_022\n",
      "MT_023\n",
      "MT_024\n",
      "MT_025\n",
      "MT_026\n",
      "MT_027\n",
      "MT_028\n",
      "MT_029\n",
      "MT_030\n",
      "MT_031\n",
      "MT_032\n",
      "MT_033\n",
      "MT_034\n",
      "MT_035\n",
      "MT_036\n",
      "MT_037\n",
      "MT_038\n",
      "MT_039\n",
      "MT_040\n",
      "MT_041\n",
      "MT_042\n",
      "MT_043\n",
      "MT_044\n",
      "MT_045\n",
      "MT_046\n",
      "MT_047\n",
      "MT_048\n",
      "MT_049\n",
      "MT_050\n",
      "MT_051\n",
      "MT_052\n",
      "MT_053\n",
      "MT_054\n",
      "MT_055\n",
      "MT_056\n",
      "MT_057\n",
      "MT_058\n",
      "MT_059\n",
      "MT_060\n",
      "MT_061\n",
      "MT_062\n",
      "MT_063\n",
      "MT_064\n",
      "MT_065\n",
      "MT_066\n",
      "MT_067\n",
      "MT_068\n",
      "MT_069\n",
      "MT_070\n",
      "MT_071\n",
      "MT_072\n",
      "MT_073\n",
      "MT_074\n",
      "MT_075\n",
      "MT_076\n",
      "MT_077\n",
      "MT_078\n",
      "MT_079\n",
      "MT_080\n",
      "MT_081\n",
      "MT_082\n",
      "MT_083\n",
      "MT_084\n",
      "MT_085\n",
      "MT_086\n",
      "MT_087\n",
      "MT_088\n",
      "MT_089\n",
      "MT_090\n",
      "MT_091\n",
      "MT_092\n",
      "MT_093\n",
      "MT_094\n",
      "MT_095\n",
      "MT_096\n",
      "MT_097\n",
      "MT_098\n",
      "MT_099\n",
      "MT_100\n",
      "MT_101\n",
      "MT_102\n",
      "MT_103\n",
      "MT_104\n",
      "MT_105\n",
      "MT_106\n",
      "MT_107\n",
      "MT_108\n",
      "MT_109\n",
      "MT_110\n",
      "MT_111\n",
      "MT_112\n",
      "MT_113\n",
      "MT_114\n",
      "MT_115\n",
      "MT_116\n",
      "MT_117\n",
      "MT_118\n",
      "MT_119\n",
      "MT_120\n",
      "MT_121\n",
      "MT_122\n",
      "MT_123\n",
      "MT_124\n",
      "MT_125\n",
      "MT_126\n",
      "MT_127\n",
      "MT_128\n",
      "MT_129\n",
      "MT_130\n",
      "MT_131\n",
      "MT_132\n",
      "MT_133\n",
      "MT_134\n",
      "MT_135\n",
      "MT_136\n",
      "MT_137\n",
      "MT_138\n",
      "MT_139\n",
      "MT_140\n",
      "MT_141\n",
      "MT_142\n",
      "MT_143\n",
      "MT_144\n",
      "MT_145\n",
      "MT_146\n",
      "MT_147\n",
      "MT_148\n",
      "MT_149\n",
      "MT_150\n",
      "MT_151\n",
      "MT_152\n",
      "MT_153\n",
      "MT_154\n",
      "MT_155\n",
      "MT_156\n",
      "MT_157\n",
      "MT_158\n",
      "MT_159\n",
      "MT_160\n",
      "MT_161\n",
      "MT_162\n",
      "MT_163\n",
      "MT_164\n",
      "MT_165\n",
      "MT_166\n",
      "MT_167\n",
      "MT_168\n",
      "MT_169\n",
      "MT_170\n",
      "MT_171\n",
      "MT_172\n",
      "MT_173\n",
      "MT_174\n",
      "MT_175\n",
      "MT_176\n",
      "MT_177\n",
      "MT_178\n",
      "MT_179\n",
      "MT_180\n",
      "MT_181\n",
      "MT_182\n",
      "MT_183\n",
      "MT_184\n",
      "MT_185\n",
      "MT_186\n",
      "MT_187\n",
      "MT_188\n",
      "MT_189\n",
      "MT_190\n",
      "MT_191\n",
      "MT_192\n",
      "MT_193\n",
      "MT_194\n",
      "MT_195\n",
      "MT_196\n",
      "MT_197\n",
      "MT_198\n",
      "MT_199\n",
      "MT_200\n",
      "MT_201\n",
      "MT_202\n",
      "MT_203\n",
      "MT_204\n",
      "MT_205\n",
      "MT_206\n",
      "MT_207\n",
      "MT_208\n",
      "MT_209\n",
      "MT_210\n",
      "MT_211\n",
      "MT_212\n",
      "MT_213\n",
      "MT_214\n",
      "MT_215\n",
      "MT_216\n",
      "MT_217\n",
      "MT_218\n",
      "MT_219\n",
      "MT_220\n",
      "MT_221\n",
      "MT_222\n",
      "MT_223\n",
      "MT_224\n",
      "MT_225\n",
      "MT_226\n",
      "MT_227\n",
      "MT_228\n",
      "MT_229\n",
      "MT_230\n",
      "MT_231\n",
      "MT_232\n",
      "MT_233\n",
      "MT_234\n",
      "MT_235\n",
      "MT_236\n",
      "MT_237\n",
      "MT_238\n",
      "MT_239\n",
      "MT_240\n",
      "MT_241\n",
      "MT_242\n",
      "MT_243\n",
      "MT_244\n",
      "MT_245\n",
      "MT_246\n",
      "MT_247\n",
      "MT_248\n",
      "MT_249\n",
      "MT_250\n",
      "MT_251\n",
      "MT_252\n",
      "MT_253\n",
      "MT_254\n",
      "MT_255\n",
      "MT_256\n",
      "MT_257\n",
      "MT_258\n",
      "MT_259\n",
      "MT_260\n",
      "MT_261\n",
      "MT_262\n",
      "MT_263\n",
      "MT_264\n",
      "MT_265\n",
      "MT_266\n",
      "MT_267\n",
      "MT_268\n",
      "MT_269\n",
      "MT_270\n",
      "MT_271\n",
      "MT_272\n",
      "MT_273\n",
      "MT_274\n",
      "MT_275\n",
      "MT_276\n",
      "MT_277\n",
      "MT_278\n",
      "MT_279\n",
      "MT_280\n",
      "MT_281\n",
      "MT_282\n",
      "MT_283\n",
      "MT_284\n",
      "MT_285\n",
      "MT_286\n",
      "MT_287\n",
      "MT_288\n",
      "MT_289\n",
      "MT_290\n",
      "MT_291\n",
      "MT_292\n",
      "MT_293\n",
      "MT_294\n",
      "MT_295\n",
      "MT_296\n",
      "MT_297\n",
      "MT_298\n",
      "MT_299\n",
      "MT_300\n",
      "MT_301\n",
      "MT_302\n",
      "MT_303\n",
      "MT_304\n",
      "MT_305\n",
      "MT_306\n",
      "MT_307\n",
      "MT_308\n",
      "MT_309\n",
      "MT_310\n",
      "MT_311\n",
      "MT_312\n",
      "MT_313\n",
      "MT_314\n",
      "MT_315\n",
      "MT_316\n",
      "MT_317\n",
      "MT_318\n",
      "MT_319\n",
      "MT_320\n",
      "MT_321\n",
      "MT_322\n",
      "MT_323\n",
      "MT_324\n",
      "MT_325\n",
      "MT_326\n",
      "MT_327\n",
      "MT_328\n",
      "MT_329\n",
      "MT_330\n",
      "MT_331\n",
      "MT_332\n",
      "MT_333\n",
      "MT_334\n",
      "MT_335\n",
      "MT_336\n",
      "MT_337\n",
      "MT_338\n",
      "MT_339\n",
      "MT_340\n",
      "MT_341\n",
      "MT_342\n",
      "MT_343\n",
      "MT_344\n",
      "MT_345\n",
      "MT_346\n",
      "MT_347\n",
      "MT_348\n",
      "MT_349\n",
      "MT_350\n",
      "MT_351\n",
      "MT_352\n",
      "MT_353\n",
      "MT_354\n",
      "MT_355\n",
      "MT_356\n",
      "MT_357\n",
      "MT_358\n",
      "MT_359\n",
      "MT_360\n",
      "MT_361\n",
      "MT_362\n",
      "MT_363\n",
      "MT_364\n",
      "MT_365\n",
      "MT_366\n",
      "MT_367\n",
      "MT_368\n",
      "MT_369\n",
      "MT_370\n"
     ]
    }
   ],
   "source": [
    "temp_df = el_resample(df)\n",
    "ds = ElDataset(temp_df, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.716713Z",
     "start_time": "2019-10-30T22:26:09.707934Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 4\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, ElDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:26.661611Z",
     "start_time": "2019-10-30T22:39:26.654545Z"
    }
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    print(f\"{STUDENT}: {total_grade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}